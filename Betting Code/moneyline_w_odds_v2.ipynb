{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request,urlopen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "import pybaseball as bb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import BaseballScrapingModule\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in cast\")\n",
    "pd.set_option('display.max_rows',20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\joshm\\OneDrive\\Documents\\Side stuff\\Baseball\\Data\"\n",
    "# data_path = r\"C:\\Users\\jmiller\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WAR</th>\n",
       "      <th>K/9</th>\n",
       "      <th>SV</th>\n",
       "      <th>ERA_norm</th>\n",
       "      <th>K9_norm</th>\n",
       "      <th>SV_norm</th>\n",
       "      <th>WAR_norm</th>\n",
       "      <th>Bullpen_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2.60</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.65</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.793220</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.9025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>PHI</td>\n",
       "      <td>3.36</td>\n",
       "      <td>5.5</td>\n",
       "      <td>10.23</td>\n",
       "      <td>26</td>\n",
       "      <td>0.766871</td>\n",
       "      <td>0.989831</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>MIN</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.2</td>\n",
       "      <td>9.44</td>\n",
       "      <td>28</td>\n",
       "      <td>0.705521</td>\n",
       "      <td>0.722034</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>BAL</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.93</td>\n",
       "      <td>31</td>\n",
       "      <td>0.634969</td>\n",
       "      <td>0.549153</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.6660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>STL</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.23</td>\n",
       "      <td>34</td>\n",
       "      <td>0.723926</td>\n",
       "      <td>0.311864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.6539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>MIA</td>\n",
       "      <td>4.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>7</td>\n",
       "      <td>0.223827</td>\n",
       "      <td>0.357333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.2616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>LAA</td>\n",
       "      <td>5.22</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9.19</td>\n",
       "      <td>8</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>ARI</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.47</td>\n",
       "      <td>9</td>\n",
       "      <td>0.274368</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.2304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>TOR</td>\n",
       "      <td>4.92</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>7.87</td>\n",
       "      <td>11</td>\n",
       "      <td>0.111913</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.1921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>COL</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7.12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.256318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.1682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9752 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season    End Date Team   ERA  WAR    K/9  SV  ERA_norm   K9_norm  \\\n",
       "0       2024  2024-07-10  CLE  2.60  4.6   9.65  33  1.000000  0.793220   \n",
       "1       2024  2024-07-10  PHI  3.36  5.5  10.23  26  0.766871  0.989831   \n",
       "2       2024  2024-07-10  MIN  3.56  3.2   9.44  28  0.705521  0.722034   \n",
       "3       2024  2024-07-10  BAL  3.79  3.0   8.93  31  0.634969  0.549153   \n",
       "4       2024  2024-07-10  STL  3.50  2.6   8.23  34  0.723926  0.311864   \n",
       "...      ...         ...  ...   ...  ...    ...  ..       ...       ...   \n",
       "9747    2024  2024-05-17  MIA  4.61  1.0   8.46   7  0.223827  0.357333   \n",
       "9748    2024  2024-05-17  LAA  5.22  0.2   9.19   8  0.003610  0.552000   \n",
       "9749    2024  2024-05-17  ARI  4.47  0.6   7.47   9  0.274368  0.093333   \n",
       "9750    2024  2024-05-17  TOR  4.92 -0.6   7.87  11  0.111913  0.200000   \n",
       "9751    2024  2024-05-17  COL  4.52  0.4   7.12   8  0.256318  0.000000   \n",
       "\n",
       "       SV_norm  WAR_norm  Bullpen_Rating  \n",
       "0     0.947368  0.869565          0.9025  \n",
       "1     0.578947  1.000000          0.8339  \n",
       "2     0.684211  0.666667          0.6946  \n",
       "3     0.842105  0.637681          0.6660  \n",
       "4     1.000000  0.579710          0.6539  \n",
       "...        ...       ...             ...  \n",
       "9747  0.000000  0.465116          0.2616  \n",
       "9748  0.090909  0.279070          0.2314  \n",
       "9749  0.181818  0.372093          0.2304  \n",
       "9750  0.363636  0.093023          0.1921  \n",
       "9751  0.090909  0.325581          0.1682  \n",
       "\n",
       "[9752 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(r\"C:\\Users\\joshm\\OneDrive\\Documents\\Side stuff\\Baseball\\bullpens.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Game</th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Home</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Rslt</th>\n",
       "      <th>PA</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>BB</th>\n",
       "      <th>IBB</th>\n",
       "      <th>SO</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>ROE</th>\n",
       "      <th>GDP</th>\n",
       "      <th>SB</th>\n",
       "      <th>CS</th>\n",
       "      <th>BA</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>OPS</th>\n",
       "      <th>LOB</th>\n",
       "      <th>NumPlayers</th>\n",
       "      <th>OppStart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-30</td>\n",
       "      <td>KCR</td>\n",
       "      <td>True</td>\n",
       "      <td>MIN</td>\n",
       "      <td>L,0-2</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.354</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>P.Lopez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>KCR</td>\n",
       "      <td>True</td>\n",
       "      <td>MIN</td>\n",
       "      <td>L,0-2</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.390</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>S.Gray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>KCR</td>\n",
       "      <td>True</td>\n",
       "      <td>MIN</td>\n",
       "      <td>L,4-7</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.494</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>J.Ryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>KCR</td>\n",
       "      <td>True</td>\n",
       "      <td>TOR</td>\n",
       "      <td>W,9-5</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.601</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>J.Berrios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>KCR</td>\n",
       "      <td>True</td>\n",
       "      <td>TOR</td>\n",
       "      <td>L,1-4</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.562</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Y.Kikuchi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9713</th>\n",
       "      <td>158</td>\n",
       "      <td>2024-09-25</td>\n",
       "      <td>MIA</td>\n",
       "      <td>False</td>\n",
       "      <td>MIN</td>\n",
       "      <td>L,3-8</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.672</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>S.Woods Richardson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9714</th>\n",
       "      <td>159</td>\n",
       "      <td>2024-09-26</td>\n",
       "      <td>MIA</td>\n",
       "      <td>False</td>\n",
       "      <td>MIN</td>\n",
       "      <td>W,8-6</td>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.672</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>D.Festa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9715</th>\n",
       "      <td>160</td>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>MIA</td>\n",
       "      <td>False</td>\n",
       "      <td>TOR</td>\n",
       "      <td>W,15-5</td>\n",
       "      <td>48</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.677</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>J.Berrios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>161</td>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>MIA</td>\n",
       "      <td>False</td>\n",
       "      <td>TOR</td>\n",
       "      <td>W,8-1</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.678</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Y.Rodriguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>162</td>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>MIA</td>\n",
       "      <td>False</td>\n",
       "      <td>TOR</td>\n",
       "      <td>W,3-1</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.678</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>R.Burr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9718 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Game        Date Team   Home  Opp    Rslt  PA  AB   R   H  2B  3B  HR  \\\n",
       "0        1  2023-03-30  KCR   True  MIN   L,0-2  33  27   0   2   1   0   0   \n",
       "1        2  2023-04-01  KCR   True  MIN   L,0-2  35  30   0   4   1   0   0   \n",
       "2        3  2023-04-02  KCR   True  MIN   L,4-7  36  33   4   6   2   0   2   \n",
       "3        4  2023-04-03  KCR   True  TOR   W,9-5  37  33   9  10   2   1   1   \n",
       "4        5  2023-04-04  KCR   True  TOR   L,1-4  31  30   1   4   0   0   1   \n",
       "...    ...         ...  ...    ...  ...     ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "9713   158  2024-09-25  MIA  False  MIN   L,3-8  39  38   3  11   2   0   1   \n",
       "9714   159  2024-09-26  MIA  False  MIN   W,8-6  58  51   8  13   4   0   0   \n",
       "9715   160  2024-09-27  MIA  False  TOR  W,15-5  48  40  15  17   2   3   3   \n",
       "9716   161  2024-09-28  MIA  False  TOR   W,8-1  39  37   8  11   3   0   1   \n",
       "9717   162  2024-09-29  MIA  False  TOR   W,3-1  36  35   3   9   1   0   0   \n",
       "\n",
       "      RBI  BB  IBB  SO  HBP  SH  SF  ROE  GDP  SB  CS     BA    OBP    SLG  \\\n",
       "0       0   5    0  11    1   0   0    0    2   0   0  0.074  0.242  0.111   \n",
       "1       0   5    0   5    0   0   0    1    2   0   0  0.105  0.250  0.140   \n",
       "2       4   3    0   9    0   0   0    0    0   0   0  0.133  0.250  0.244   \n",
       "3       9   3    0  11    1   0   0    0    0   2   0  0.179  0.284  0.317   \n",
       "4       1   1    0   7    0   0   0    0    0   0   0  0.170  0.262  0.301   \n",
       "...   ...  ..  ...  ..  ...  ..  ..  ...  ...  ..  ..    ...    ...    ...   \n",
       "9713    3   1    0  16    0   0   0    0    0   0   0  0.242  0.298  0.375   \n",
       "9714    7   6    1  20    0   0   1    0    0   3   1  0.242  0.298  0.374   \n",
       "9715   14   7    0   8    0   1   0    0    1   0   0  0.243  0.300  0.378   \n",
       "9716    8   2    0   8    0   0   0    0    0   1   0  0.244  0.300  0.378   \n",
       "9717    3   1    0   8    0   0   0    0    0   0   1  0.244  0.300  0.378   \n",
       "\n",
       "        OPS  LOB  NumPlayers            OppStart  \n",
       "0     0.354    6           9             P.Lopez  \n",
       "1     0.390    8          10              S.Gray  \n",
       "2     0.494    5           9              J.Ryan  \n",
       "3     0.601    4           9           J.Berrios  \n",
       "4     0.562    3          10           Y.Kikuchi  \n",
       "...     ...  ...         ...                 ...  \n",
       "9713  0.672    9           9  S.Woods Richardson  \n",
       "9714  0.672   15          14             D.Festa  \n",
       "9715  0.677    6          11           J.Berrios  \n",
       "9716  0.678    4           9         Y.Rodriguez  \n",
       "9717  0.678    6           9              R.Burr  \n",
       "\n",
       "[9718 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = pd.read_csv(r\"C:\\Users\\joshm\\OneDrive\\Documents\\Side stuff\\Baseball\\team_gamelogs.csv\")\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-04-01',\n",
       " '2024-03-28',\n",
       " '2024-09-13',\n",
       " '2023-07-14',\n",
       " '2023-04-08',\n",
       " '2023-04-05',\n",
       " '2023-07-26',\n",
       " '2023-05-10',\n",
       " '2024-09-30',\n",
       " '2024-08-11',\n",
       " '2024-05-04',\n",
       " '2023-05-20',\n",
       " '2024-08-27',\n",
       " '2024-05-15',\n",
       " '2024-06-11',\n",
       " '2023-06-29',\n",
       " '2024-03-20',\n",
       " '2024-05-21',\n",
       " '2024-07-29',\n",
       " '2024-06-29',\n",
       " '2024-08-14',\n",
       " '2024-07-19',\n",
       " '2023-05-19',\n",
       " '2023-08-29',\n",
       " '2024-04-19',\n",
       " '2024-04-09',\n",
       " '2023-09-21',\n",
       " '2024-06-30',\n",
       " '2024-07-01',\n",
       " '2024-07-26',\n",
       " '2024-05-10',\n",
       " '2024-08-24',\n",
       " '2023-07-28',\n",
       " '2024-09-03',\n",
       " '2023-05-23',\n",
       " '2023-04-25',\n",
       " '2024-06-04',\n",
       " '2023-08-09',\n",
       " '2023-05-04',\n",
       " '2024-06-05',\n",
       " '2023-05-14']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_dates = list(set(test1['Date'].to_list()).difference(set(test['End Date'].to_list())))\n",
    "needed_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Failed to retrieve CSV data.\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Failed to retrieve CSV data.\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Failed to retrieve CSV data.\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Failed to retrieve CSV data.\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Failed to retrieve CSV data.\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n"
     ]
    }
   ],
   "source": [
    "from BaseballScrapingModule import BaseballScraper\n",
    "\n",
    "data_pull = BaseballScraper()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for game_date in pd.to_datetime(needed_dates):\n",
    "    temp = data_pull.rankBullpens(game_date.year, game_date)\n",
    "    df = pd.concat([df, temp])\n",
    "if 'bullpens.csv' in os.listdir(data_path):\n",
    "    old_df = pd.read_csv(os.path.join(data_path, 'bullpens.csv'))\n",
    "    df = pd.concat([old_df, df]).drop_duplicates(subset=['Team', 'Season','End Date'], keep='last')\n",
    "    df['End Date'] = pd.to_datetime(df['End Date'])\n",
    "    df.sort_values('End Date', inplace=True)\n",
    "df.to_csv(os.path.join(data_path, 'bullpens.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr_convert = teams_abbr = {\"AZ\" : 'ARI',\n",
    "    \"ARI\": 'ARI',\n",
    "    \"LAD\" : 'LAD',\n",
    "    \"SD\": 'SDP',\n",
    "    \"SF\": 'SFG',\n",
    "    \"COL\": 'COL',\n",
    "    \"HOU\" : 'HOU',\n",
    "    \"TEX\" : 'TEX',\n",
    "    \"SEA\": 'SEA',\n",
    "    \"LAA\": 'LAA',\n",
    "    \"OAK\": 'OAK',\n",
    "    \"MIL\": 'MIL',\n",
    "    \"CHC\": 'CHC',\n",
    "    'Chi. Cubs': 'CHC',\n",
    "    \"CIN\": 'CIN',\n",
    "    \"PIT\": 'PIT',\n",
    "    \"STL\": 'STL',\n",
    "    \"MIN\": 'MIN',\n",
    "    \"DET\": 'DET',\n",
    "    'Detroit': 'DET',\n",
    "    \"CLE\": 'CLE',\n",
    "    \"CWS\": 'CHW',\n",
    "    'CHW':'CHW',\n",
    "    'Chi. White Sox' : 'CHW',\n",
    "    \"KC\": 'KCR',\n",
    "    \"ATL\": 'ATL',\n",
    "    \"PHI\": 'PHI',\n",
    "    \"MIA\": 'MIA',\n",
    "    'Miami': 'MIA',\n",
    "    \"NYM\": 'NYM',\n",
    "    \"WSH\": 'WSN',\n",
    "    'Washington':'WSN',\n",
    "    'WAS':'WSN',\n",
    "    \"BAL\": 'BAL',\n",
    "    \"TB\": 'TBR',\n",
    "    \"TOR\": 'TOR',\n",
    "    \"NYY\": 'NYY',\n",
    "    \"BOS\": 'BOS',\n",
    "    'Boston':'BOS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USED TO CREATE CSV THAT CONTAINS PITCHER CATEGORIES ###\n",
    "def categorizePitchers():\n",
    "    ### GET PITCHERS FROM DESIRED SEASONS ###\n",
    "    pitchers = bb.fg_pitching_data(2023, 2024, qual=10)\n",
    "    ### GET IDS FOR ALL THOSE PITCHERS ###\n",
    "    pitchers_ids = bb.playerid_reverse_lookup(pitchers['IDfg'], key_type='fangraphs')\n",
    "\n",
    "    names, mlbIDs, bbrefIDs, fgIDs, years = [], [], [], [], []\n",
    "    final_stats = []\n",
    "    for i in range(len(pitchers_ids)):\n",
    "        print('Pitcher {0} of {1}'.format(i, len(pitchers_ids)), end='\\n')\n",
    "        ### GRAB DIFFERENT SEASONS FOR A PITCHER (ACCOUNT FOR THE CHANGE THEY MAY HAVE THROUGH SEASONS) ###\n",
    "        start_year, end_year = int(pitchers_ids.iloc[i, 6]), int(pitchers_ids.iloc[i, 7])+1\n",
    "        ### MAKE SURE THE DATA WE GET IS JUST 2021+ ###\n",
    "        if start_year <= 2022: start_year = 2023\n",
    "        for year in range(start_year, end_year):\n",
    "            try:\n",
    "                ### GRABBING SPLITS MAY ERROR, SKIP THOSE WHO DO ###\n",
    "                pitcher_splits = bb.get_splits(playerid=pitchers_ids.iloc[i, 4], year=year, pitching_splits=True, player_info=True)\n",
    "                ##########################################################################\n",
    "                ### CATEGORIZATION BASED ON SPLITS/PITCH SPEED AND SPIN ##################\n",
    "                ##########################################################################\n",
    "                ### GRAB WHAT HANDEDNESS THE PITCHER IS ###\n",
    "                if pitcher_splits[1]['Throws'] == 'Right ':\n",
    "                    stats = np.array([0])\n",
    "                elif pitcher_splits[1]['Throws'] == 'Left ':\n",
    "                    stats = np.array([1])\n",
    "                else:\n",
    "                    stats = np.array([2])\n",
    "                ### APPEND ROWS OF INTEREST TO OUR STATS ###\n",
    "                stats = np.append(stats, [pitcher_splits[0].loc['Platoon Splits', 'vs LHB'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Platoon Splits', 'vs RHB'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Home or Away', 'Home'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Home or Away', 'Away'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Hit Trajectory', 'Ground Balls'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Hit Trajectory', 'Fly Balls'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Hit Trajectory', 'Line Drives'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Game Conditions', 'Day'].to_numpy(),\n",
    "                                            pitcher_splits[0].loc['Game Conditions', 'Night'].to_numpy()])\n",
    "                ### GET AVG SPIN AND AVG SPEED OF PITCH TYPES ###\n",
    "                pitch_spin = bb.statcast_pitcher_pitch_arsenal(year=year, minP=0, arsenal_type='avg_spin')\n",
    "                stats = np.append(stats, pitch_spin.loc[pitch_spin['pitcher']==pitchers_ids.iloc[i, 2], pitch_spin.columns[2:]].to_numpy())\n",
    "\n",
    "                pitch_speed = bb.statcast_pitcher_pitch_arsenal(year=year, minP=0, arsenal_type='avg_speed')\n",
    "                stats = np.append(stats, pitch_speed.loc[pitch_speed['pitcher']==pitchers_ids.iloc[i, 2], pitch_speed.columns[2:]].to_numpy())\n",
    "\n",
    "                stats = pd.Series(stats).replace(pd.NA, np.nan).to_numpy()\n",
    "\n",
    "                if len(np.nan_to_num(stats))==273:\n",
    "                    ### FOR FUTURE CREATING OF PITCHER CATEGORY TABLE ###\n",
    "                    final_stats.append(np.nan_to_num(stats))\n",
    "                    names.append(pitchers_ids.iloc[i, 0]+', '+pitchers_ids.iloc[i, 1])\n",
    "                    mlbIDs.append(pitchers_ids.iloc[i, 2])\n",
    "                    bbrefIDs.append(pitchers_ids.iloc[i, 4])\n",
    "                    fgIDs.append(pitchers_ids.iloc[i, 5])\n",
    "                    years.append(year)\n",
    "                else:\n",
    "                    print('Pitcher {0} only had {1} data columns for season {2}, skipping.'.format(pitchers_ids.iloc[i,4], len(np.nan_to_num(stats)), year))\n",
    "            except:\n",
    "                print('Pitcher {0} encountered errors for season {1}, skipping.'.format(pitchers_ids.iloc[i, 4], year))\n",
    "\n",
    "    final_stats = np.array(final_stats)\n",
    "    kmeans = KMeans().fit(final_stats)\n",
    "    pitcher_categories = pd.DataFrame({'Pitcher':names, 'Season':years, 'mlbID':mlbIDs, 'bbrefID':bbrefIDs, 'fgID':fgIDs, 'Categorization': kmeans.labels_})\n",
    "    pitcher_categories['Pitcher'] = pitcher_categories['Pitcher'].apply(unidecode)\n",
    "\n",
    "    return pitcher_categories\n",
    "    # pitcher_categories.to_csv(os.path.join(data_path, \"pitcher_categories.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizePitchers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams = set(teams_abbr.values())\n",
    "all_team_gamelogs_batting = pd.DataFrame()\n",
    "\n",
    "for season in [2023, 2024]:\n",
    "    for team in all_teams:\n",
    "        gamelog_batting = bb.team_game_logs(season, team, 'batting')\n",
    "        gamelog_batting['Date'] = pd.to_datetime(gamelog_batting['Date'].str[:6].str.strip() + ', {0}'.format(season))\n",
    "        gamelog_batting['OppStart'] = gamelog_batting['OppStart'].str.split('(').str[0]\n",
    "        gamelog_batting['OppStart'] = gamelog_batting['OppStart'].apply(unidecode)\n",
    "        gamelog_batting.insert(2, 'Team', team)\n",
    "        all_team_gamelogs_batting = pd.concat([all_team_gamelogs_batting, gamelog_batting.drop('Thr', axis=1)])\n",
    "        \n",
    "all_team_gamelogs_batting.to_csv(os.path.join(data_path, \"team_gamelogs.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structureGames():\n",
    "    combined_gamelog = pd.read_csv(os.path.join(data_path, \"team_gamelogs.csv\"))\n",
    "    combined_gamelog['Date'] = pd.to_datetime(combined_gamelog['Date'])\n",
    "    combined_gamelog['Season'] = combined_gamelog['Date'].dt.year\n",
    "    combined_gamelog = combined_gamelog.sort_values('Date')\n",
    "    combined_gamelog['DoubleHeader'] = combined_gamelog[['Date', 'Team', 'Opp']].duplicated()\n",
    "    combined_gamelog['1B'] = combined_gamelog['H'] - (combined_gamelog['2B']+combined_gamelog['3B']+combined_gamelog['HR'])\n",
    "    # combined_gamelog.rename({'H':'1B'}, axis=1, inplace=True)\n",
    "\n",
    "    roster = pd.read_csv(os.path.join(data_path, \"rosters.csv\")).rename({'bbref_id':'bbrefID', 'Name':'Pitcher'}, axis=1)\n",
    "    pitcher_cat = pd.read_csv(os.path.join(data_path, \"pitcher_categories.csv\"), usecols=['Season', 'bbrefID', 'Categorization'])\n",
    "    pitcher_cat = pd.merge(pitcher_cat, roster, 'left', ['Season', 'bbrefID']).rename({'Team':'Opp'}, axis=1)\n",
    "    pitcher_cat['OppStart'] = pitcher_cat['Pitcher'].str.split(' ').str[0].str[0] + '.' +  pitcher_cat['Pitcher'].str.split(' ').str[1]\n",
    "    pitcher_cat = pitcher_cat[['OppStart', 'Season', 'Opp', 'Categorization']]\n",
    "\n",
    "    combined_gamelog = pd.merge(combined_gamelog, pitcher_cat, 'left', ['OppStart', 'Season', 'Opp'])\n",
    "\n",
    "    home_teams, away_teams = combined_gamelog.loc[combined_gamelog['Home']==True], combined_gamelog.loc[combined_gamelog['Home']!=True]\n",
    "    combined_gamelog = pd.merge(home_teams, away_teams, 'inner', left_on=['Date','Team','Opp', 'DoubleHeader'], right_on=['Date','Opp','Team', 'DoubleHeader'],suffixes=['_home', '_away'])\n",
    "    combined_gamelog = combined_gamelog.drop(['Game_home', 'Home_home', 'Opp_home', 'Rslt_home', 'BA_home', 'OBP_home', 'SLG_home', 'OPS_home', 'NumPlayers_home', 'Season_home', 'DoubleHeader',\n",
    "                                            'Game_away', 'Home_away', 'Opp_away', 'Rslt_away', 'BA_away', 'OBP_away', 'SLG_away', 'OPS_away', 'NumPlayers_away', 'Season_away'], axis=1)\n",
    "    combined_gamelog['Result'] = (combined_gamelog['R_home']>combined_gamelog['R_away']).astype(int)\n",
    "    combined_gamelog = combined_gamelog.dropna(subset=['Categorization_home', 'Categorization_away']).reset_index(drop=True)\n",
    "    return combined_gamelog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USED TO GET ALL ARRAYS UP TO A GIVEN DATE. USEFUL FOR SIMULATING AND GRABBING THE ARRAYS UP TO A GAME DAY TO TRAIN ON BEFORE PREDICTING ###\n",
    "# col_home =['Team_home','PA_home','AB_home','R_home','H_home','1B_home','2B_home','3B_home','HR_home','BB_home','SO_home','HBP_home',\n",
    "#                                     'SH_home','ROE_home','SB_home','CS_home','LOB_home']\n",
    "# col_away = ['Team_away','PA_away','AB_away','R_away','H_away','1B_away','2B_away','3B_away','HR_away','BB_away','SO_away','HBP_away',\n",
    "#                                     'SH_away','ROE_away','SB_away','CS_away','LOB_away']\n",
    "col_home =['Team_home','PA_home','AB_home','R_home','H_home','1B_home','2B_home','3B_home','HR_home','BB_home','SO_home','HBP_home',\n",
    "                                    'SH_home','SB_home','CS_home','LOB_home']\n",
    "col_away = ['Team_away','PA_away','AB_away','R_away','H_away','1B_away','2B_away','3B_away','HR_away','BB_away','SO_away','HBP_away',\n",
    "                                    'SH_away','SB_away','CS_away','LOB_away']\n",
    "def getArraysUpToDate(odds, gamelogs, current_game_date, data_pull):\n",
    "\n",
    "    gamelogs = gamelogs[gamelogs['Date']<current_game_date]\n",
    "    # gamelogs = gamelogs.loc[gamelogs['Date'].dt.year==2023]\n",
    "    game_stats, game_results, all_home_odds, all_away_odds, all_home_teams, all_away_teams, dates = [], [], [], [], [], [], []\n",
    "    for row in range(len(gamelogs)):\n",
    "        ### GETTING HOME TEAM LAST GAMES STATS ###\n",
    "        date, team, opp, pitcher, pitcher_cat, runs_home, runs_away = gamelogs.loc[row, ['Date', 'Team_home', 'Team_away', 'OppStart_home', 'Categorization_home', 'R_home', 'R_away']]\n",
    "        ### GET BULLPEN RANKING UP TO DATE ###\n",
    "        bullpens = data_pull.rankBullpens(date.year, date)\n",
    "        ### GET GAME RESULT ### \n",
    "        game_outcome = (runs_home>runs_away).astype(int)\n",
    "        ### GET GAME ODDS ###\n",
    "        try:\n",
    "            home_odds = odds.loc[(odds['Date']==date)&(odds['Home Team']==team)&(odds['Away Team']==opp), 'Home W Odds'].to_list()[0]\n",
    "            away_odds = odds.loc[(odds['Date']==date)&(odds['Home Team']==team)&(odds['Away Team']==opp), 'Away W Odds'].to_list()[0]\n",
    "        except:\n",
    "            print('No odds for game on ', date, ' for ', team, ' - ', opp)\n",
    "        ### GET GAMES TEAM HAD AGAINST SPECIFIC PITCHER THIS SEASON ###\n",
    "        against_pitcher_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['OppStart_home']==pitcher)), \n",
    "                                col_home]\n",
    "\n",
    "        against_pitcher_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['OppStart_away']==pitcher)&(gamelogs['Team_away']==team)), \n",
    "                                col_away]\n",
    "        against_pitcher_away.columns = col_home\n",
    "        against_pitcher = pd.concat([against_pitcher_away, against_pitcher_home])\n",
    "        ### GET GAMES TEAM HAD AGAINST PITCHER CATEGORY THIS SEASON ###\n",
    "        against_pitcher_cat_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['Categorization_home']==pitcher_cat)&(gamelogs['OppStart_home']!=pitcher)),\n",
    "                                    col_home]\n",
    "        \n",
    "        against_pitcher_cat_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Categorization_away']==pitcher_cat)&(gamelogs['OppStart_away']!=pitcher)&(gamelogs['Team_away']==team)),\n",
    "                                    col_away]\n",
    "        against_pitcher_cat_away.columns = col_home\n",
    "        against_pitcher_cat = pd.concat([against_pitcher_cat_away, against_pitcher_cat_home])\n",
    "        # against_pitcher_cat = against_pitcher_cat[-5:]\n",
    "        # against_pitcher_cat = pd.DataFrame()\n",
    "        ### GET GAMES TEAM HAD AGAINST OPPOSING TEAM THIS SEASON ###\n",
    "        against_team_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['Team_away']==opp)&(gamelogs['OppStart_home']!=pitcher)&(gamelogs['Categorization_home']!=pitcher_cat)),\n",
    "                                col_home]\n",
    "        \n",
    "        against_team_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&(((gamelogs['Team_home']==opp)&(gamelogs['Team_away']==team)&(gamelogs['OppStart_away']!=pitcher)&(gamelogs['Categorization_away']!=pitcher_cat))),\n",
    "                                col_away]\n",
    "        against_team_away.columns = col_home\n",
    "        against_team = pd.concat([against_team_away, against_team_home])\n",
    "        # against_team = against_team[-5:]\n",
    "        \n",
    "        home_team_last = []\n",
    "        if len(against_pitcher)+len(against_pitcher_cat)+len(against_team)>3:\n",
    "            home_team_last = pd.concat([against_pitcher, against_pitcher_cat, against_team]).groupby('Team_home', as_index=False).mean().drop('Team_home',axis=1)\n",
    "            home_team_last.loc[~home_team_last['AB_home'].isna(), 'BA_home'] = np.round(home_team_last.loc[~home_team_last['AB_home'].isna(), 'H_home']/home_team_last.loc[~home_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            home_team_last.loc[~home_team_last['PA_home'].isna(), 'OBP_home'] = np.round((home_team_last.loc[~home_team_last['PA_home'].isna(), 'H_home']+home_team_last.loc[~home_team_last['PA_home'].isna(), 'BB_home'])\\\n",
    "                                                                                /home_team_last.loc[~home_team_last['PA_home'].isna(), 'PA_home'],3)\n",
    "            home_team_last.loc[~home_team_last['AB_home'].isna(), 'SLG_home'] = np.round((home_team_last.loc[~home_team_last['AB_home'].isna(), '1B_home']+2*home_team_last.loc[~home_team_last['AB_home'].isna(), '2B_home']+\\\n",
    "                                                                                3*home_team_last.loc[~home_team_last['AB_home'].isna(), '3B_home']+4*home_team_last.loc[~home_team_last['AB_home'].isna(), 'HR_home'])\\\n",
    "                                                                                /home_team_last.loc[~home_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            home_team_last['BP_home'] = bullpens.loc[(bullpens['Team']==team)&(bullpens['Season']==date.year), 'Bullpen_Rating'].to_list()[0]\n",
    "\n",
    "        ### GETTING AWAY TEAM LAST GAMES STATS ###\n",
    "        date, team, opp, pitcher, pitcher_cat, runs_home, runs_away = gamelogs.loc[row, ['Date', 'Team_away', 'Team_home', 'OppStart_away', 'Categorization_away', 'R_home', 'R_away']]\n",
    "        ### GET GAMES TEAM HAD AGAINST SPECIFIC PITCHER THIS SEASON ###\n",
    "        against_pitcher_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['OppStart_home']==pitcher)), \n",
    "                                col_home]\n",
    "\n",
    "        against_pitcher_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['OppStart_away']==pitcher)&(gamelogs['Team_away']==team)), \n",
    "                                col_away]\n",
    "        against_pitcher_away.columns = col_home\n",
    "        against_pitcher = pd.concat([against_pitcher_away, against_pitcher_home])\n",
    "        ### GET GAMES TEAM HAD AGAINST PITCHER CATEGORY THIS SEASON ###\n",
    "        against_pitcher_cat_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['Categorization_home']==pitcher_cat)&(gamelogs['OppStart_home']!=pitcher)),\n",
    "                                    col_home]\n",
    "        \n",
    "        against_pitcher_cat_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Categorization_away']==pitcher_cat)&(gamelogs['OppStart_away']!=pitcher)&(gamelogs['Team_away']==team)),\n",
    "                                    col_away]\n",
    "        against_pitcher_cat_away.columns = col_home\n",
    "        against_pitcher_cat = pd.concat([against_pitcher_cat_away, against_pitcher_cat_home])\n",
    "        # against_pitcher_cat = against_pitcher_cat[-5:]\n",
    "        # against_pitcher_cat = pd.DataFrame()\n",
    "        ### GET GAMES TEAM HAD AGAINST OPPOSING TEAM THIS SEASON ###\n",
    "        against_team_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['Team_away']==opp)&(gamelogs['OppStart_home']!=pitcher)&(gamelogs['Categorization_home']!=pitcher_cat)),\n",
    "                                col_home]\n",
    "        \n",
    "        against_team_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&(((gamelogs['Team_home']==opp)&(gamelogs['Team_away']==team)&(gamelogs['OppStart_away']!=pitcher)&(gamelogs['Categorization_away']!=pitcher_cat))),\n",
    "                                col_away]\n",
    "        against_team_away.columns = col_home\n",
    "        against_team = pd.concat([against_team_away, against_team_home])\n",
    "        # against_team = against_team[-5:]\n",
    "        \n",
    "        away_team_last = []\n",
    "        if len(against_pitcher)+len(against_pitcher_cat)+len(against_team)>3:\n",
    "            away_team_last = pd.concat([against_pitcher, against_pitcher_cat, against_team]).groupby('Team_home', as_index=False).mean().drop('Team_home',axis=1)\n",
    "            away_team_last.loc[~away_team_last['AB_home'].isna(), 'BA_home'] = np.round(away_team_last.loc[~away_team_last['AB_home'].isna(), 'H_home']/away_team_last.loc[~away_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            away_team_last.loc[~away_team_last['PA_home'].isna(), 'OBP_home'] = np.round((away_team_last.loc[~away_team_last['PA_home'].isna(), 'H_home']+away_team_last.loc[~away_team_last['PA_home'].isna(), 'BB_home'])\\\n",
    "                                                                                /away_team_last.loc[~away_team_last['PA_home'].isna(), 'PA_home'],3)\n",
    "            away_team_last.loc[~away_team_last['AB_home'].isna(), 'SLG_home'] = np.round((away_team_last.loc[~away_team_last['AB_home'].isna(), '1B_home']+2*away_team_last.loc[~away_team_last['AB_home'].isna(), '2B_home']+\\\n",
    "                                                                                3*away_team_last.loc[~away_team_last['AB_home'].isna(), '3B_home']+4*away_team_last.loc[~away_team_last['AB_home'].isna(), 'HR_home'])\\\n",
    "                                                                                /away_team_last.loc[~away_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            away_team_last['BP_home'] = bullpens.loc[(bullpens['Team']==team)&(bullpens['Season']==date.year), 'Bullpen_Rating'].to_list()[0]\n",
    "        # print(row, ':', opp, len(home_team_last), team, len(away_team_last))\n",
    "        if (len(home_team_last)!=0) & (len(away_team_last)!=0):\n",
    "            if (False in np.isnan(home_team_last.to_numpy())) & (False in np.isnan(away_team_last.to_numpy())) & (~np.isnan(home_odds)) & (~np.isnan(away_odds)):\n",
    "                game_results.append(game_outcome)\n",
    "                game_stats.append(np.round(pd.concat([home_team_last, away_team_last], axis=1),3).to_numpy())\n",
    "                all_home_odds.append(home_odds)\n",
    "                all_away_odds.append(away_odds)\n",
    "                all_home_teams.append(opp)\n",
    "                all_away_teams.append(team)\n",
    "                dates.append(date)\n",
    "    \n",
    "    return game_stats, game_results, all_home_odds, all_away_odds, all_home_teams, all_away_teams, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RETURNS THE AGGREGATED LAST GAME STATS FOR TEAMS PLAYING ON A GIVEN DAY. USEFUL FOR GETTING THE ARRAY IN WHICH WE'LL PREDICT HOME TEAM WINS ###\n",
    "def getArraysForDate(odds, gamelogs, date, teams, opps, pitcher_homes, pitcher_cat_homes, pitcher_aways, pitcher_cat_aways, results, data_pull):\n",
    "\n",
    "    game_stats, all_home_odds, all_away_odds, new_results = [], [], [], []\n",
    "    bullpens = data_pull.rankBullpens(date.year, date)\n",
    "    for i in range(len(teams)):\n",
    "        team, opp, pitcher_home, pitcher_cat_home, pitcher_away, pitcher_cat_away = teams[i], opps[i], pitcher_homes[i], pitcher_cat_homes[i], pitcher_aways[i], pitcher_cat_aways[i]\n",
    "        ### GETTING HOME TEAM LAST GAMES STATS ###\n",
    "        #date, team, opp, pitcher, pitcher_cat, runs_home, runs_away = gamelogs.loc[row, ['Date', 'Team_home', 'Team_away', 'OppStart_home', 'Categorization_home', 'R_home', 'R_away']]\n",
    "        ### GET GAME RESULT ### \n",
    "        #game_outcome = (runs_home>runs_away).astype(int)\n",
    "        ### GET GAME ODDS ###\n",
    "        try:\n",
    "            home_odds = odds.loc[(odds['Date']==date)&(odds['Home Team']==team)&(odds['Away Team']==opp), 'Home W Odds'].to_list()[0]\n",
    "            away_odds = odds.loc[(odds['Date']==date)&(odds['Home Team']==team)&(odds['Away Team']==opp), 'Away W Odds'].to_list()[0]\n",
    "        except:\n",
    "            print('No odds for game on ', date, ' for ', team, ' - ', opp)\n",
    "        ### GET GAMES TEAM HAD AGAINST SPECIFIC PITCHER THIS SEASON ###\n",
    "        against_pitcher_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['OppStart_home']==pitcher_home)), \n",
    "                                col_home]\n",
    "\n",
    "        against_pitcher_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['OppStart_away']==pitcher_home)&(gamelogs['Team_away']==team)), \n",
    "                                col_away]\n",
    "        against_pitcher_away.columns = col_home\n",
    "        against_pitcher = pd.concat([against_pitcher_away, against_pitcher_home])\n",
    "        ### GET GAMES TEAM HAD AGAINST PITCHER CATEGORY THIS SEASON ###\n",
    "        against_pitcher_cat_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['Categorization_home']==pitcher_cat_home)&(gamelogs['OppStart_home']!=pitcher_home)),\n",
    "                                    col_home]\n",
    "        \n",
    "        against_pitcher_cat_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Categorization_away']==pitcher_cat_home)&(gamelogs['OppStart_away']!=pitcher_home)&(gamelogs['Team_away']==team)),\n",
    "                                    col_away]\n",
    "        against_pitcher_cat_away.columns = col_home\n",
    "        against_pitcher_cat = pd.concat([against_pitcher_cat_away, against_pitcher_cat_home])\n",
    "        # against_pitcher_cat = against_pitcher_cat[-5:]\n",
    "        ### GET GAMES TEAM HAD AGAINST OPPOSING TEAM THIS SEASON ###\n",
    "        against_team_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==team)&(gamelogs['Team_away']==opp)&(gamelogs['OppStart_home']!=pitcher_home)&(gamelogs['Categorization_home']!=pitcher_cat_home)),\n",
    "                                col_home]\n",
    "        \n",
    "        against_team_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&(((gamelogs['Team_home']==opp)&(gamelogs['Team_away']==team)&(gamelogs['OppStart_away']!=pitcher_home)&(gamelogs['Categorization_away']!=pitcher_cat_home))),\n",
    "                                col_away]\n",
    "        against_team_away.columns = col_home\n",
    "        against_team = pd.concat([against_team_away, against_team_home])\n",
    "        # against_team = against_team[-5:]\n",
    "        \n",
    "        home_team_last = []\n",
    "        if len(against_pitcher)+len(against_pitcher_cat)+len(against_team)>3:\n",
    "            home_team_last = pd.concat([against_pitcher, against_pitcher_cat, against_team]).groupby('Team_home', as_index=False).mean().drop('Team_home',axis=1)\n",
    "            home_team_last.loc[~home_team_last['AB_home'].isna(), 'BA_home'] = np.round(home_team_last.loc[~home_team_last['AB_home'].isna(), 'H_home']/home_team_last.loc[~home_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            home_team_last.loc[~home_team_last['PA_home'].isna(), 'OBP_home'] = np.round((home_team_last.loc[~home_team_last['PA_home'].isna(), 'H_home']+home_team_last.loc[~home_team_last['PA_home'].isna(), 'BB_home'])\\\n",
    "                                                                                /home_team_last.loc[~home_team_last['PA_home'].isna(), 'PA_home'],3)\n",
    "            home_team_last.loc[~home_team_last['AB_home'].isna(), 'SLG_home'] = np.round((home_team_last.loc[~home_team_last['AB_home'].isna(), '1B_home']+2*home_team_last.loc[~home_team_last['AB_home'].isna(), '2B_home']+\\\n",
    "                                                                                3*home_team_last.loc[~home_team_last['AB_home'].isna(), '3B_home']+4*home_team_last.loc[~home_team_last['AB_home'].isna(), 'HR_home'])\\\n",
    "                                                                                /home_team_last.loc[~home_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            home_team_last['BP_home'] = bullpens.loc[(bullpens['Team']==team)&(bullpens['Season']==date.year), 'Bullpen_Rating'].to_list()[0]\n",
    "        ##########################################################################################################################################################################################################\n",
    "        ### GETTING AWAY TEAM LAST GAMES STATS ###\n",
    "        # date, team, opp, pitcher, pitcher_cat, runs_home, runs_away = gamelogs.loc[row, ['Date', 'Team_away', 'Team_home', 'OppStart_away', 'Categorization_away', 'R_home', 'R_away']]\n",
    "        ### GET GAMES TEAM HAD AGAINST SPECIFIC PITCHER THIS SEASON ###\n",
    "        against_pitcher_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==opp)&(gamelogs['OppStart_home']==pitcher_away)), \n",
    "                                col_home]\n",
    "\n",
    "        against_pitcher_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['OppStart_away']==pitcher_away)&(gamelogs['Team_away']==opp)), \n",
    "                                col_away]\n",
    "        against_pitcher_away.columns = col_home\n",
    "        against_pitcher = pd.concat([against_pitcher_away, against_pitcher_home])\n",
    "        ### GET GAMES TEAM HAD AGAINST PITCHER CATEGORY THIS SEASON ###\n",
    "        against_pitcher_cat_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==opp)&(gamelogs['Categorization_home']==pitcher_cat_away)&(gamelogs['OppStart_home']!=pitcher_away)),\n",
    "                                    col_home]\n",
    "        \n",
    "        against_pitcher_cat_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Categorization_away']==pitcher_cat_away)&(gamelogs['OppStart_away']!=pitcher_away)&(gamelogs['Team_away']==opp)),\n",
    "                                    col_away]\n",
    "        against_pitcher_cat_away.columns = col_home\n",
    "        against_pitcher_cat = pd.concat([against_pitcher_cat_away, against_pitcher_cat_home])\n",
    "        # against_pitcher_cat = against_pitcher_cat[-5:]\n",
    "        ### GET GAMES TEAM HAD AGAINST OPPOSING TEAM THIS SEASON ###\n",
    "        against_team_home = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&((gamelogs['Team_home']==opp)&(gamelogs['Team_away']==team)&(gamelogs['OppStart_home']!=pitcher_away)&(gamelogs['Categorization_home']!=pitcher_cat_away)),\n",
    "                                col_home]\n",
    "        \n",
    "        against_team_away = gamelogs.loc[(gamelogs['Date'].dt.year==date.year)&(gamelogs['Date']<date)&(((gamelogs['Team_home']==team)&(gamelogs['Team_away']==opp)&(gamelogs['OppStart_away']!=pitcher_away)&(gamelogs['Categorization_away']!=pitcher_cat_away))),\n",
    "                               col_away]\n",
    "        against_team_away.columns = col_home\n",
    "        against_team = pd.concat([against_team_away, against_team_home])\n",
    "        # against_team = against_team[-5:]\n",
    "        \n",
    "        away_team_last = []\n",
    "        if len(against_pitcher)+len(against_pitcher_cat)+len(against_team)>3:\n",
    "            away_team_last = pd.concat([against_pitcher, against_pitcher_cat, against_team]).groupby('Team_home', as_index=False).mean().drop('Team_home',axis=1)\n",
    "            away_team_last.loc[~away_team_last['AB_home'].isna(), 'BA_home'] = np.round(away_team_last.loc[~away_team_last['AB_home'].isna(), 'H_home']/away_team_last.loc[~away_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            away_team_last.loc[~away_team_last['PA_home'].isna(), 'OBP_home'] = np.round((away_team_last.loc[~away_team_last['PA_home'].isna(), 'H_home']+away_team_last.loc[~away_team_last['PA_home'].isna(), 'BB_home'])\\\n",
    "                                                                                /away_team_last.loc[~away_team_last['PA_home'].isna(), 'PA_home'],3)\n",
    "            away_team_last.loc[~away_team_last['AB_home'].isna(), 'SLG_home'] = np.round((away_team_last.loc[~away_team_last['AB_home'].isna(), '1B_home']+2*away_team_last.loc[~away_team_last['AB_home'].isna(), '2B_home']+\\\n",
    "                                                                                3*away_team_last.loc[~away_team_last['AB_home'].isna(), '3B_home']+4*away_team_last.loc[~away_team_last['AB_home'].isna(), 'HR_home'])\\\n",
    "                                                                                /away_team_last.loc[~away_team_last['AB_home'].isna(), 'AB_home'],3)\n",
    "            away_team_last['BP_home'] = bullpens.loc[(bullpens['Team']==opp)&(bullpens['Season']==date.year), 'Bullpen_Rating'].to_list()[0]\n",
    "\n",
    "        # print(row, ':', opp, len(home_team_last), team, len(away_team_last))\n",
    "        if (len(home_team_last)!=0) & (len(away_team_last)!=0):\n",
    "            if (False in np.isnan(home_team_last.to_numpy())) & (False in np.isnan(away_team_last.to_numpy())) & (~np.isnan(home_odds)) & (~np.isnan(away_odds)):\n",
    "                #game_results.append(game_outcome)\n",
    "                game_stats.append(np.round(pd.concat([home_team_last, away_team_last], axis=1),3).to_numpy())\n",
    "                all_home_odds.append(home_odds)\n",
    "                all_away_odds.append(away_odds)\n",
    "                new_results.append(results[i])\n",
    "        \n",
    "    return game_stats, all_home_odds, all_away_odds, new_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Failed to retrieve CSV data.\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Fetching CSV data for season 2023 from FanGraphs...\n"
     ]
    }
   ],
   "source": [
    "### PULLING ALL STATS FOR GAMELOGS ###\n",
    "odds = pd.read_csv(os.path.join(data_path, \"odds_list.csv\"))\n",
    "odds['Date'] = pd.to_datetime(odds['Date'])\n",
    "odds['Home Team'], odds['Away Team'] = odds['Home Team'].apply(lambda x: teams_abbr[x]), odds['Away Team'].apply(lambda x: teams_abbr[x])\n",
    "\n",
    "# bullpens = pd.read_csv(os.path.join(data_path, \"bullpens.csv\"))\n",
    "data_pull = BaseballScrapingModule.BaseballScraper()\n",
    "\n",
    "gamelogs = structureGames()\n",
    "\n",
    "game_stats, game_results, all_home_odds, all_away_odds, all_home_teams, all_away_teams, dates = getArraysUpToDate(odds, gamelogs, pd.to_datetime('today'), data_pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write output\n",
    "np_game_stats, np_game_results = np.array(game_stats).reshape([len(game_stats), len(game_stats[0][0])]), np.array(game_results)\n",
    "output = pd.DataFrame(np_game_stats)\n",
    "output.columns = ['PA_home','AB_home','R_home','H_home','1B_home','2B_home','3B_home','HR_home','BB_home','SO_home','HBP_home','SH_home','SB_home','CS_home','LOB_home','BA_home','OBP_home','SLG_home', 'BP_home',\n",
    "                  'PA_away','AB_away','R_away','H_away','1B_away','2B_away','3B_away','HR_away','BB_away','SO_away','HBP_away','SH_away','SB_away','CS_away','LOB_away','BA_away','OBP_away','SLG_away', 'BP_away']\n",
    "output['Result'] = np_game_results\n",
    "output.to_csv(os.path.join(data_path, 'compiled_stats.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PULLING STATS FOR A SINGLE GAME ###\n",
    "odds = pd.read_csv(os.path.join(data_path, \"odds_list.csv\"))\n",
    "odds['Date'] = pd.to_datetime(odds['Date'])\n",
    "odds['Home Team'], odds['Away Team'] = odds['Home Team'].apply(lambda x: teams_abbr[x]), odds['Away Team'].apply(lambda x: teams_abbr[x])\n",
    "\n",
    "gamelogs = structureGames()\n",
    "\n",
    "date, teams, opps = pd.to_datetime('2023-06-11'), ['NYY'], ['BOS']\n",
    "pitcher_homes, pitcher_cat_homes, pitcher_aways, pitcher_cat_aways = ['B.Bello'], [5.0], ['C.Schmidt'], [3.0] \n",
    "\n",
    "game_stats, all_home_odds, all_away_odds = getArraysForDate(odds, gamelogs, date, teams, opps, pitcher_homes, pitcher_cat_homes, pitcher_aways, pitcher_cat_aways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1,len(s)+1))\n",
    "\n",
    "def calculateWinnings(df, acc_balance, wins, bets_made, parlays_made, parlays_won):\n",
    "\n",
    "    df['Parlay'] = 0\n",
    "\n",
    "    possible_parlays = [team for team in powerset(df['HomeTeam']) if len(team)>1]\n",
    "    parlay = pd.DataFrame()\n",
    "    for i in possible_parlays:\n",
    "        temp_parlay = df.loc[df['HomeTeam'].isin(i)]\n",
    "        temp_parlay = temp_parlay.groupby('Date', as_index=False).agg({'HomeTeam':lambda x:list(x), 'AwayTeam':lambda x:list(x), 'Result':lambda x:list(x), \n",
    "                                                                    'Prediction':lambda x:list(x), 'Prob':'prod', 'Odds':'prod'})\n",
    "        temp_parlay['Prob'], temp_parlay['Odds'] = round(temp_parlay['Prob'],4), round(temp_parlay['Odds'],2)\n",
    "        if temp_parlay['Prob'].to_list()[0]>=0.5:\n",
    "            parlay = pd.concat([parlay, temp_parlay])\n",
    "            parlay['Parlay'] = 1\n",
    "\n",
    "    df = pd.concat([df, parlay])\n",
    "\n",
    "    df['kelly'] = round(df['Prob'] - (1-df['Prob'])/(df['Odds']-1),2)\n",
    "    df['frac_kelly'] = round(df['kelly']/2,2)\n",
    "\n",
    "    df = df.loc[df['frac_kelly']>=0.05]\n",
    "\n",
    "    while sum(df['frac_kelly']) >=0.7:\n",
    "        df['frac_kelly'] = round(df['frac_kelly']/2,2)\n",
    "\n",
    "    df.sort_values('Prob', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if len(df)==0:\n",
    "        print('No bets made.')\n",
    "    else:\n",
    "        for i in range(len(df)):\n",
    "            df.loc[i, 'WagerAmt'] = round(df.loc[i, 'frac_kelly']*acc_balance,2)\n",
    "            acc_balance -= round(df.loc[i, 'frac_kelly']*acc_balance,2)\n",
    "\n",
    "        df['Winnings'] = 0\n",
    "        df.loc[df['Result']==df['Prediction'], 'Winnings'] = round(df.loc[df['Result']==df['Prediction'], 'WagerAmt']*df.loc[df['Result']==df['Prediction'], 'Odds'],2)\n",
    "\n",
    "        df['Profit'] = round(df['Winnings'] - df['WagerAmt'],2)\n",
    "\n",
    "        acc_balance += round(df['Winnings'].sum(),2)\n",
    "        wins += sum((df['Prediction']==df['Result']).astype(int))\n",
    "        bets_made += len(df)\n",
    "        parlays_made += len(df.loc[df['Parlay']==1])\n",
    "        parlays_won += len(df.loc[(df['Prediction']==df['Result'])&(df['Parlay']==1)])\n",
    "\n",
    "    return round(acc_balance,2), wins, bets_made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-07 00:00:00\n",
      "Fetching CSV data for season 2024 from FanGraphs...\n",
      "Loading CSV data into a DataFrame...\n",
      "Bullpens ranked. \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m### GET ALL PREVIOUS DATA TO TRAIN ON ###\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m game_stats, game_results, all_home_odds, all_away_odds, all_home_teams, all_away_teams, dates \u001b[38;5;241m=\u001b[39m \u001b[43mgetArraysUpToDate\u001b[49m\u001b[43m(\u001b[49m\u001b[43modds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamelogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbullpens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m game_stats, game_results \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(game_stats)\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;28mlen\u001b[39m(game_stats), \u001b[38;5;28mlen\u001b[39m(game_stats[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])]), np\u001b[38;5;241m.\u001b[39marray(game_results)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#gradientboost\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# gbc = GradientBoostingClassifier(criterion='squared_error',n_estimators=100, learning_rate=0.15, max_depth=75).fit(game_stats, game_results)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#randomforest\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# forest = RandomForestClassifier(criterion='entropy',max_depth=10,min_samples_split= 10,n_estimators= 200).fit(game_stats, game_results)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#svm\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 63\u001b[0m, in \u001b[0;36mgetArraysUpToDate\u001b[1;34m(odds, gamelogs, current_game_date, bullpens)\u001b[0m\n\u001b[0;32m     58\u001b[0m     home_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPA_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOBP_home\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround((home_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPA_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39mhome_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPA_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBB_home\u001b[39m\u001b[38;5;124m'\u001b[39m])\\\n\u001b[0;32m     59\u001b[0m                                                                         \u001b[38;5;241m/\u001b[39mhome_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPA_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPA_home\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     60\u001b[0m     home_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSLG_home\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround((home_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1B_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mhome_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2B_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m     61\u001b[0m                                                                         \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mhome_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3B_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mhome_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHR_home\u001b[39m\u001b[38;5;124m'\u001b[39m])\\\n\u001b[0;32m     62\u001b[0m                                                                         \u001b[38;5;241m/\u001b[39mhome_team_last\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mhome_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAB_home\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m     home_team_last[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBP_home\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mbullpens\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbullpens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTeam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mteam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbullpens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSeason\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBullpen_Rating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m### GETTING AWAY TEAM LAST GAMES STATS ###\u001b[39;00m\n\u001b[0;32m     66\u001b[0m date, team, opp, pitcher, pitcher_cat, runs_home, runs_away \u001b[38;5;241m=\u001b[39m gamelogs\u001b[38;5;241m.\u001b[39mloc[row, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam_away\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTeam_home\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOppStart_away\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategorization_away\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR_home\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR_away\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#set balance\n",
    "acc_balance, wins, bets_made, parlays_made, parlays_won = 1000, 0, 0, 0, 0\n",
    "#set seed for recreating\n",
    "# random_seed = 54\n",
    "# np.random.seed(random_seed)\n",
    "# random.seed(random_seed)\n",
    "### WHEN NOT SIMULATING, WE WILL NEED TO PULL FROM THE DAYS SCHEDULE ###\n",
    "### BELIEVE I KEEP ORIGINAL GETARRAYS FUNCTION TO GET THE AGGREGATES UP TO THE GIVEN DAY FOR MODEL TRAINING. THEN RUN THE NEW GETARRAY TO GET THE AGGREGATED STATS FOR PREDICTING ###\n",
    "odds = pd.read_csv(os.path.join(data_path, \"odds_list.csv\"))\n",
    "odds['Date'] = pd.to_datetime(odds['Date'])\n",
    "odds['Home Team'], odds['Away Team'] = odds['Home Team'].apply(lambda x: teams_abbr[x]), odds['Away Team'].apply(lambda x: teams_abbr[x])\n",
    "\n",
    "data_pull = BaseballScrapingModule.BaseballScraper()\n",
    "\n",
    "# bullpens = pd.read_csv(os.path.join(data_path, \"bullpens.csv\"))\n",
    "\n",
    "gamelogs = structureGames()\n",
    "\n",
    "simulation_dates = sorted(list(set(gamelogs.loc[gamelogs['Date'].dt.year==2024, 'Date'].to_list())))[12:]\n",
    "\n",
    "for date in simulation_dates:\n",
    "    print(date)\n",
    "# for date in [pd.to_datetime('2024-06-28'), pd.to_datetime('2024-06-29'), pd.to_datetime('2024-06-30'),pd.to_datetime('2024-07-01'), pd.to_datetime('2024-07-02'),\n",
    "#              pd.to_datetime('2024-07-03'), pd.to_datetime('2024-07-04'), pd.to_datetime('2024-07-05'),pd.to_datetime('2024-07-06'), pd.to_datetime('2024-07-07')]:\n",
    "    if acc_balance < 5:\n",
    "        print(\"You're broke.\")\n",
    "        break\n",
    "    ### GET ALL PREVIOUS DATA TO TRAIN ON ###\n",
    "    game_stats, game_results, all_home_odds, all_away_odds, all_home_teams, all_away_teams, dates = getArraysUpToDate(odds, gamelogs, date, data_pull)\n",
    "    game_stats, game_results = np.array(game_stats).reshape([len(game_stats), len(game_stats[0][0])]), np.array(game_results)\n",
    "\n",
    "    #gradientboost\n",
    "    # gbc = GradientBoostingClassifier(criterion='squared_error',n_estimators=100, learning_rate=0.15, max_depth=75).fit(game_stats, game_results)\n",
    "    #randomforest\n",
    "    # forest = RandomForestClassifier(criterion='entropy',max_depth=10,min_samples_split= 10,n_estimators= 200).fit(game_stats, game_results)\n",
    "    #svm\n",
    "    svm = SVC(C=10, gamma='scale', kernel='linear', probability=True).fit(game_stats, game_results)\n",
    "    #xgboost\n",
    "    params = {'num_class':2,\n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 3,\n",
    "            'n_estimators': 200,\n",
    "            'subsample': 0.8,\n",
    "            'eval_metric': 'logloss'}\n",
    "    bst = xgb.XGBClassifier(objective='multi:softmax', **params).fit(game_stats, game_results)\n",
    "    ### GET TODAY'S AGG STATS TO MAKE PREDICTION FROM TRAINED MODEL ###\n",
    "    todays_game = gamelogs.loc[gamelogs['Date']==date]\n",
    "    teams, opps = todays_game['Team_home'].to_list(), todays_game['Team_away'].to_list()\n",
    "    pitcher_homes, pitcher_cat_homes = todays_game['OppStart_home'].to_list(), todays_game['Categorization_home'].to_list()\n",
    "    pitcher_aways, pitcher_cat_aways = todays_game['OppStart_away'].to_list(), todays_game['Categorization_away'].to_list()\n",
    "\n",
    "    results = todays_game['Result'].to_numpy()\n",
    "\n",
    "    game_stats, all_home_odds, all_away_odds, new_results = getArraysForDate(odds, gamelogs, date, teams, opps, pitcher_homes, pitcher_cat_homes, pitcher_aways, pitcher_cat_aways, results,data_pull)\n",
    "    if len(game_stats)==0:\n",
    "        print(f\"Not enough data, skipping {date}.\")\n",
    "        continue\n",
    "    game_stats, new_results = np.array(game_stats).reshape([len(game_stats), len(game_stats[0][0])]), np.array(new_results)\n",
    "    print('# Games: ', len(new_results), '\\n')\n",
    "    #gradient predict\n",
    "    # grad_pred = gbc.predict(game_stats)\n",
    "    # grad_pred_probs = gbc.predict_proba(game_stats)[:,1]\n",
    "    # print('Gradient', ': ', accuracy_score(new_results, grad_pred), ': ', sum(grad_pred)/len(grad_pred), '\\n') \n",
    "    #forest predict\n",
    "    # for_pred = forest.predict(game_stats)\n",
    "    # for_pred_probs = forest.predict_proba(game_stats)[:,1]\n",
    "    # print('Forest: ', accuracy_score(new_results, for_pred),'', sum(for_pred)/len(for_pred), '\\n')\n",
    "    #svm predict\n",
    "    svm_pred = svm.predict(game_stats)\n",
    "    svm_pred_probs = svm.predict_proba(game_stats)[:,1]\n",
    "    print('SVM: ', accuracy_score(new_results, svm_pred),'', sum(svm_pred)/len(svm_pred), '\\n')\n",
    "    #xg predict\n",
    "    xg_pred = bst.predict(game_stats)\n",
    "    xg_pred_probs = bst.predict_proba(game_stats)[:,1]\n",
    "    print('XG: ', accuracy_score(new_results, xg_pred),'', sum(xg_pred)/len(xg_pred), '\\n')\n",
    "    #combine predictions\n",
    "    # bets = for_pred  +  xg_pred + svm_pred\n",
    "    bets = xg_pred + svm_pred\n",
    "    teams_new, opps_new, results_new, predictions, pred_probs, home_odds_new, away_odds_new = [], [], [], [], [], [], []\n",
    "    for i in range(len(bets)):\n",
    "        if (bets[i]==2) | (bets[i]==0):\n",
    "            teams_new.append(teams[i])\n",
    "            opps_new.append(opps[i])\n",
    "            results_new.append(new_results[i])\n",
    "            predictions.append(bets[i]//2)\n",
    "            pred_probs.append(round((xg_pred_probs[i]+svm_pred_probs[i])/2, 4))\n",
    "            home_odds_new.append(all_home_odds[i])\n",
    "            away_odds_new.append(all_away_odds[i])\n",
    "\n",
    "    ### accuracy of all three combined\n",
    "    if len(predictions)>0:\n",
    "        print('Combined: ', accuracy_score(results_new, predictions),'', sum(predictions)/len(predictions), ': ', len(predictions))\n",
    "\n",
    "        df = pd.DataFrame({'Date':[date]*len(predictions), 'HomeTeam':teams_new, 'AwayTeam':opps_new, 'Result':results_new, 'Prediction':predictions, 'Prob':pred_probs,\n",
    "                'HomeOdds':home_odds_new, 'AwayOdds':away_odds_new})\n",
    "        df.loc[df['Prediction']==0, 'Prob'] = 1 - df.loc[df['Prediction']==0, 'Prob']\n",
    "        df.loc[df['Prediction']==0, 'Odds'] = df.loc[df['Prediction']==0, 'AwayOdds']\n",
    "        df.loc[df['Prediction']==1, 'Odds'] = df.loc[df['Prediction']==1, 'HomeOdds']\n",
    "        df.drop(['HomeOdds', 'AwayOdds'],axis=1,inplace=True)\n",
    "\n",
    "        acc_balance, wins, bets_made = calculateWinnings(df, acc_balance, wins, bets_made, parlays_made, parlays_won)\n",
    "        print('Balance: ', acc_balance, '\\n', 'Wins: ', wins, '\\n','Bets: ',bets_made, '\\n','Parlays Won - Made: ', parlays_won, ' - ', parlays_made)\n",
    "    else:\n",
    "        print('No agreement.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Team</th>\n",
       "      <th>ERA</th>\n",
       "      <th>WAR</th>\n",
       "      <th>K/9</th>\n",
       "      <th>SV</th>\n",
       "      <th>ERA_norm</th>\n",
       "      <th>K9_norm</th>\n",
       "      <th>SV_norm</th>\n",
       "      <th>WAR_norm</th>\n",
       "      <th>Bullpen_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2.57</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.39</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>MIL</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.81</td>\n",
       "      <td>53</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>ATL</td>\n",
       "      <td>3.32</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.92</td>\n",
       "      <td>40</td>\n",
       "      <td>0.735915</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024</td>\n",
       "      <td>NYM</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.8</td>\n",
       "      <td>10.61</td>\n",
       "      <td>39</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.6582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024</td>\n",
       "      <td>SDP</td>\n",
       "      <td>3.78</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.38</td>\n",
       "      <td>44</td>\n",
       "      <td>0.573944</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.6456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024</td>\n",
       "      <td>ARI</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.23</td>\n",
       "      <td>38</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.3619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024</td>\n",
       "      <td>LAA</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.2</td>\n",
       "      <td>8.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.143382</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>0.3545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024</td>\n",
       "      <td>CHW</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9.24</td>\n",
       "      <td>21</td>\n",
       "      <td>0.239437</td>\n",
       "      <td>0.496324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303922</td>\n",
       "      <td>0.2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024</td>\n",
       "      <td>COL</td>\n",
       "      <td>5.41</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>7.89</td>\n",
       "      <td>37</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024</td>\n",
       "      <td>TOR</td>\n",
       "      <td>4.82</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>7.99</td>\n",
       "      <td>36</td>\n",
       "      <td>0.207746</td>\n",
       "      <td>0.036765</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Season Team   ERA  WAR    K/9  SV  ERA_norm   K9_norm   SV_norm  WAR_norm  \\\n",
       "0     2024  CLE  2.57  7.7   9.39  53  1.000000  0.551471  0.941176  1.000000   \n",
       "3     2024  MIL  3.11  5.9   8.81  53  0.809859  0.338235  0.941176  0.823529   \n",
       "2     2024  ATL  3.32  6.1   9.92  40  0.735915  0.746324  0.558824  0.843137   \n",
       "12    2024  NYM  4.03  3.8  10.61  39  0.485915  1.000000  0.529412  0.617647   \n",
       "6     2024  SDP  3.78  5.5   9.38  44  0.573944  0.547794  0.676471  0.784314   \n",
       "..     ...  ...   ...  ...    ...  ..       ...       ...       ...       ...   \n",
       "21    2024  ARI  4.41  2.3   8.23  38  0.352113  0.125000  0.500000  0.470588   \n",
       "26    2024  LAA  3.99  1.2   8.28  35  0.500000  0.143382  0.411765  0.362745   \n",
       "27    2024  CHW  4.73  0.6   9.24  21  0.239437  0.496324  0.000000  0.303922   \n",
       "28    2024  COL  5.41 -0.2   7.89  37  0.000000  0.000000  0.470588  0.225490   \n",
       "29    2024  TOR  4.82 -2.5   7.99  36  0.207746  0.036765  0.441176  0.000000   \n",
       "\n",
       "    Bullpen_Rating  \n",
       "0           0.8732  \n",
       "3           0.7282  \n",
       "2           0.7210  \n",
       "12          0.6582  \n",
       "6           0.6456  \n",
       "..             ...  \n",
       "21          0.3619  \n",
       "26          0.3545  \n",
       "27          0.2599  \n",
       "28          0.1740  \n",
       "29          0.1714  \n",
       "\n",
       "[30 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bullpens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_game_stats, np_game_results = np.array(game_stats).reshape([len(game_stats), len(game_stats[0][0])]), np.array(game_results)\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# game_stats = min_max_scaler.fit_transform(game_stats)\n",
    "\n",
    "stats_train, stats_test, results_train, results_test, h_odds_train, h_odds_test, a_odds_train, a_odds_test, \\\n",
    "    h_team_train, h_team_test, a_team_train, a_team_test = train_test_split(np_game_stats, np_game_results, all_home_odds, all_away_odds, all_home_teams, all_away_teams, test_size=0.2) \n",
    "\n",
    "# stats_train, stats_test = np.array(stats_train).reshape([len(stats_train), len(game_stats[0][0])]), np.array(stats_test).reshape([len(stats_test), len(game_stats[0][0])])\n",
    "# results_train, results_test = np.array(results_train), np.array(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient:  0.5273556231003039  0.5106382978723404 \n",
      "\n",
      "Forest:  0.560790273556231  0.7355623100303952 \n",
      "\n",
      "Neural:  0.5212765957446809  1.0 \n",
      "\n",
      "SVM:  0.5516717325227963  0.5987841945288754 \n",
      "\n",
      "XG:  0.5349544072948328  0.5972644376899696 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### last best models ###\n",
    "#gradientboost\n",
    "# gbc = GradientBoostingClassifier(n_estimators=150, learning_rate=0.01, max_depth=5, random_state=40).fit(stats_train, results_train)\n",
    "gbc = GradientBoostingClassifier(random_state=40, criterion='squared_error',n_estimators=100, learning_rate=0.15, max_depth=75).fit(stats_train, results_train)\n",
    "grad_pred = gbc.predict(stats_test)\n",
    "grad_pred_probs = gbc.predict_proba(stats_test)\n",
    "print('Gradient: ', accuracy_score(results_test, grad_pred), '', sum(grad_pred)/len(grad_pred), '\\n')\n",
    "#randomforest\n",
    "# forest = RandomForestClassifier(random_state=40, n_estimators=100, criterion='log_loss', min_samples_split=2, min_samples_leaf=3, min_weight_fraction_leaf=0.2).fit(stats_train, results_train)\n",
    "forest = RandomForestClassifier(random_state=40, n_estimators=120, criterion='entropy', min_weight_fraction_leaf=0.1, max_depth=100).fit(stats_train, results_train)\n",
    "for_pred = forest.predict(stats_test)\n",
    "for_pred_probs = forest.predict_proba(stats_test)\n",
    "print('Forest: ', accuracy_score(results_test, for_pred),'', sum(for_pred)/len(for_pred), '\\n')\n",
    "#neural\n",
    "clf = MLPClassifier(random_state=40, hidden_layer_sizes=(100, 100), activation='tanh', solver='adam', alpha=0.001, learning_rate='constant', \n",
    "                    learning_rate_init=0.01).fit(stats_train, results_train)\n",
    "neural_pred = clf.predict(stats_test)\n",
    "neural_pred_probs = clf.predict_proba(stats_test)\n",
    "print('Neural: ', accuracy_score(results_test, neural_pred),'', sum(neural_pred)/len(neural_pred), '\\n')\n",
    "#svm\n",
    "# svm = SVC(C=2, kernel='sigmoid', gamma='scale', tol=0.1, random_state=40).fit(stats_train, results_train)\n",
    "svm = SVC(random_state=40, C=0.5, kernel='linear',gamma='scale', tol=0.1, probability=True).fit(stats_train, results_train)\n",
    "svm_pred = svm.predict(stats_test)\n",
    "svm_pred_probs = svm.predict_proba(stats_test)[:,1]\n",
    "print('SVM: ', accuracy_score(results_test, svm_pred),'', sum(svm_pred)/len(svm_pred), '\\n')\n",
    "#xgboost\n",
    "params = {'booster':'gbtree',\n",
    "'num_class': 2, \n",
    "'max_depth': 4,  \n",
    "'learning_rate': 0.2,  \n",
    "'eval_metric': 'mlogloss',\n",
    "'lambda':1.2}\n",
    "bst = xgb.XGBClassifier(objective='multi:softmax', **params).fit(stats_train, results_train)\n",
    "xg_pred = bst.predict(stats_test)\n",
    "xg_pred_probs = bst.predict_proba(stats_test)[:,1]\n",
    "print('XG: ', accuracy_score(results_test, xg_pred),'', sum(xg_pred)/len(xg_pred), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:04:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy Comparison with Hyperparameter Tuning:\n",
      "                 Model  Accuracy  \\\n",
      "0        Decision Tree  0.541033   \n",
      "1        Random Forest  0.563830   \n",
      "2  K-Nearest Neighbors  0.528875   \n",
      "3          Naive Bayes  0.550152   \n",
      "4                  SVM  0.569909   \n",
      "5    Gradient Boosting  0.554711   \n",
      "6              XGBoost  0.577508   \n",
      "\n",
      "                                         Best Params  \n",
      "0  {'criterion': 'entropy', 'max_depth': 5, 'min_...  \n",
      "1  {'criterion': 'entropy', 'max_depth': 10, 'min...  \n",
      "2  {'metric': 'manhattan', 'n_neighbors': 3, 'wei...  \n",
      "3                            Default parameters used  \n",
      "4    {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}  \n",
      "5  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...  \n",
      "6  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(os.path.join(data_path, 'compiled_stats.csv'))\n",
    "\n",
    "# Prepare the feature set and target variable\n",
    "X = data.drop(columns=['Result'])\n",
    "y = data['Result']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models and their hyperparameters for GridSearchCV\n",
    "param_grids = {\n",
    "    \"Decision Tree\": {\n",
    "        \"model\": DecisionTreeClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_depth\": [5, 10, 15, None],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [10, 20, None],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "            \"criterion\": [\"gini\", \"entropy\"]\n",
    "        }\n",
    "    },\n",
    "    \"K-Nearest Neighbors\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            \"n_neighbors\": [3, 5, 7, 9],\n",
    "            \"weights\": [\"uniform\", \"distance\"],\n",
    "            \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "        }\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        \"model\": GaussianNB(),\n",
    "        \"params\": {}  # Naive Bayes does not have significant tunable hyperparameters\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"model\": SVC(random_state=42),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5, 10],\n",
    "            \"subsample\": [0.8, 1.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV and collect results\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "for name, config in param_grids.items():\n",
    "    model = config[\"model\"]\n",
    "    param_grid = config[\"params\"]\n",
    "\n",
    "    if param_grid:  # Apply grid search if parameters are provided\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        best_models[name] = best_model\n",
    "    else:  # No grid search for models without significant parameters (Naive Bayes)\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        best_params = \"Default parameters used\"\n",
    "        best_models[name] = best_model\n",
    "\n",
    "    # Predict on the test set and compute accuracy\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results.append({\"Model\": name, \"Accuracy\": acc, \"Best Params\": best_params})\n",
    "\n",
    "# Display the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Accuracy Comparison with Hyperparameter Tuning:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.541033</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.528875</td>\n",
       "      <td>{'metric': 'manhattan', 'n_neighbors': 3, 'wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.550152</td>\n",
       "      <td>Default parameters used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.569909</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.554711</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.577508</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  \\\n",
       "0        Decision Tree  0.541033   \n",
       "1        Random Forest  0.563830   \n",
       "2  K-Nearest Neighbors  0.528875   \n",
       "3          Naive Bayes  0.550152   \n",
       "4                  SVM  0.569909   \n",
       "5    Gradient Boosting  0.554711   \n",
       "6              XGBoost  0.577508   \n",
       "\n",
       "                                         Best Params  \n",
       "0  {'criterion': 'entropy', 'max_depth': 5, 'min_...  \n",
       "1  {'criterion': 'entropy', 'max_depth': 10, 'min...  \n",
       "2  {'metric': 'manhattan', 'n_neighbors': 3, 'wei...  \n",
       "3                            Default parameters used  \n",
       "4    {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}  \n",
       "5  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...  \n",
       "6  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joshm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:23:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {'num_class':2,\n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 3,\n",
    "            'n_estimators': 200,\n",
    "            'subsample': 0.8,\n",
    "            'eval_metric': 'logloss'}\n",
    "bst = xgb.XGBClassifier(use_label_encoder=False,objective='multi:softmax', **params, random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5820668693009119"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = bst.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
